{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7a9bbf-4d55-47bd-a5f4-55454d159ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/15 23:25:18 WARN Utils: Your hostname, chenyideMacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.31.64 instead (on interface en0)\n",
      "24/11/15 23:25:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/15 23:25:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 59052)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.6/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymysql\n",
    "import cryptography\n",
    "from datetime import datetime, date\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, IntegerType, ArrayType, DoubleType\n",
    "from hashlib import sha256, md5\n",
    "from util import *\n",
    "from table_config import *\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.utils import to_undirected, k_hop_subgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db054198-61fb-4e73-83a5-35e701a6028b",
   "metadata": {},
   "source": [
    "## SQL Statements (Create Partition Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c78e4a-3fa2-4c36-845f-107d809ee76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS edge_data\n",
    "(\n",
    "    src_id BIGINT,\n",
    "    dst_id BIGINT,\n",
    "    weight FLOAT,\n",
    "    edge_type VARCHAR(255)\n",
    ")\n",
    "PARTITION BY LIST COLUMNS(edge_type)(\n",
    "    PARTITION class_to_class VALUES IN ('class_to_class'),\n",
    "    PARTITION class_to_method VALUES IN ('class_contain_method'),\n",
    "    PARTITION method_to_class VALUES IN ('method_to_class'),\n",
    "    PARTITION method_to_method VALUES IN ('method_to_method')\n",
    "    );\n",
    "\n",
    "INSERT INTO edge_data\n",
    "SELECT src_id, dst_id, weight, type FROM edge_class_to_class\n",
    "UNION ALL\n",
    "SELECT src_id, dst_id, weight, type FROM edge_class_to_method\n",
    "UNION ALL\n",
    "SELECT src_id, dst_id, weight, type FROM edge_method_to_class\n",
    "UNION ALL\n",
    "SELECT src_id, dst_id, weight, type FROM edge_method_to_method;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "799ceab4-8344-45af-8a54-35d2a8b2379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "select * from edge_data\n",
    "'''\n",
    "# sp_res = pull_data(sql)\n",
    "\n",
    "# c2c_sp_df.select('src_id', 'dst_id').toPandas()\n",
    "# sp_res.select('src_id', 'dst_id').where(sp_res['edge_type']=='class_to_class').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a45dd17-0cc8-4008-ade3-2f99e4f47ebf",
   "metadata": {},
   "source": [
    "## Graph Data (Use Class Node Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb07b632-304b-4367-99a9-14a91e581f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_res = pull_data(\n",
    "    '''\n",
    "    select * from class_processed_data\n",
    "    '''\n",
    ")\n",
    "\n",
    "c2c_sp_df = pull_data(\n",
    "    '''\n",
    "    select * from edge_class_to_class\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb355dd7-ec2d-4bbb-b7e1-0fb25ff66cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/15 23:25:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Test Node\n",
    "target_class_node = sp_res.where('isTest == 1').distinct()\n",
    "target_class_node_list = target_class_node.toPandas()['index'].tolist()\n",
    "\n",
    "# target_method_node = new_sp_df2.where('isTest == 1').distinct()\n",
    "# target_method_node_list = target_method_node.toPandas()['index'].tolist()\n",
    "\n",
    "# Source Class Node\n",
    "test_list, class_list = find_class_by_test(sp_res.toPandas(), target_class_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d06ca8e-0e41-48fe-9614-165415f85bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.from_numpy(c2c_sp_df.select('src_id', 'dst_id').toPandas().values).T\n",
    "\n",
    "test_edge_index, test_node_map = remap_node_edge(test_list, edge_index)\n",
    "class_edge_index, class_node_map = remap_node_edge(class_list, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ec49e4-5770-4bf8-af3e-c62764609bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_edge_index_t = np.array(class_edge_index).T\n",
    "test_edge_index_t = np.array(test_edge_index).T\n",
    "test_edge_index_ori = [[test_node_map[src], test_node_map[dst]] for src, dst in test_edge_index_t]\n",
    "\n",
    "labels = np.zeros(len(class_node_map))\n",
    "\n",
    "for pair in class_edge_index_t:\n",
    "    src_id = pair[0]\n",
    "    dst_id = pair[1]\n",
    "    if [class_node_map[src_id], class_node_map[dst_id]] in test_edge_index_ori:\n",
    "        labels[src_id] = 1\n",
    "        labels[dst_id] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc96384f-83a7-44cf-9ba3-d9400bd10cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_string = sp_res.select(\n",
    "    'packageName',\n",
    "    'className'\n",
    ").toPandas().iloc[list(class_node_map.values())]\n",
    "\n",
    "node_feature_double = sp_res.select(\n",
    "    'line_count', \n",
    "    'import_count', \n",
    "    'super_class_count',\n",
    "    'implement_count',\n",
    "    'method_count',\n",
    "    'constructor_count',\n",
    "    'constructor_dep_count',\n",
    "    'sub_class_count'\n",
    ").toPandas().iloc[list(class_node_map.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c226272e-f706-4833-83ed-91c3975b67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node feature\n",
    "columns_1 = ['id', 'label', 'feature_map_string', 'feature_map_double']\n",
    "node_feature = pd.DataFrame(columns=columns_1)\n",
    "node_feature['id'] = list(class_node_map.keys())\n",
    "node_feature['label'] = labels.tolist()\n",
    "node_feature['feature_map_string'] = node_feature_string.values.tolist()\n",
    "node_feature['feature_map_double'] = node_feature_double.values.tolist()\n",
    "node_feature = node_feature.astype({'id': int, 'label': int, 'feature_map_string': 'string', 'feature_map_double': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e933a613-3cc0-43fb-86a4-b7327992968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index\n",
    "columns_2 = ['src_id', 'dst_id', 'weight', 'type']\n",
    "edge_index = pd.DataFrame(columns=columns_2)\n",
    "edge_index['src_id'] = class_edge_index[0]\n",
    "edge_index['dst_id'] = class_edge_index[1]\n",
    "edge_index['weight'] = 1\n",
    "edge_index['weight'] = edge_index['weight'].astype(float)\n",
    "edge_index['type'] = 'class_to_class'\n",
    "edge_index = edge_index.astype({'src_id': int, 'dst_id': int, 'weight': float, 'type': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3de2f098-27ee-4f9a-9749-48c92bcd5428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp_node_feature = convert_empty_list_to_NULL(spark.createDataFrame(node_feature))\n",
    "sp_edge_index = convert_empty_list_to_NULL(spark.createDataFrame(edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4da81d2-404a-44d3-82e6-b94a09d3fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# push_to_mysql(sp_node_feature.rdd, 'final_node_feature', node_feature_table_columns)\n",
    "# push_to_mysql(sp_edge_index.rdd, 'final_edge_index', edge_index_table_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038cd37-e2ec-45d5-9564-34b26b4a06b3",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d4b77ac-5f8c-4e6c-b936-88128d5bc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4c08ec1-8871-4afb-bef0-390822e14dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature['feature_map_string'] = node_feature['feature_map_string'].apply(eval)\n",
    "node_feature['feature_map_double'] = node_feature['feature_map_double'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a799e6d2-6c65-4bf1-b122-ec1de477558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/Users/chenyi/Documents/sag/Final_Project/data/train'\n",
    "edge_index_save_path = f'{save_path}/edge_index/class_to_class'\n",
    "node_feature_save_path = f'{save_path}/node_feature'\n",
    "os.makedirs(edge_index_save_path, exist_ok=True)\n",
    "os.makedirs(node_feature_save_path, exist_ok=True)\n",
    "pq.write_table(pa.Table.from_pandas(edge_index), f'{edge_index_save_path}/edge_index.pq', compression=None)\n",
    "pq.write_table(pa.Table.from_pandas(node_feature), f'{node_feature_save_path}/node_feature.pq', compression=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ff112-63c5-4fb7-b87f-5de247abdca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
